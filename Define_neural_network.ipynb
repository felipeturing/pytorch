{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Define-neural-network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+XicJmbUtMrbBpGXAmPFU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felipeturing/pytorch/blob/turing/Define_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-WpWzAPQi8g"
      },
      "source": [
        "# DEFINING A NEURAL NETWORK IN PYTORCH\n",
        "\n",
        "In PyTorch, neural networks can be constructed using the `torch.nn` package. It's necessary must install torch with `pip install torch`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8F7VAJoRCPE"
      },
      "source": [
        "### Imports\n",
        "\n",
        "An `nn.Module` contain layers, and a method forward  (input) that returns the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74bLVRJcRIX0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F # to manipulate the forward func. between layers"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRHs9GM8Rewq"
      },
      "source": [
        "### Define, initiliaze, pass forward the neural network\n",
        "\n",
        "For this notebook we're gonna built a convolution network. The main features are\n",
        "\n",
        "1. Extract certain features like edges detection, sharpness, blurriness, etc.\n",
        "2. Use an small matrix as a kernel, i.e each element of an image is in its local neighbors (convolution operation)\n",
        "\n",
        "Using convolution, we will define our model to take 1 input image channel, and output match our target of 10 labels representing numbers 0 through 9. We will follow a standard **MNIST** algorithm.\n",
        "\n",
        "**Important** : An `__init__` function that references `nn.Module` is where you define the fully connected layers in your neural network.\n",
        "\n",
        "We're gonna use CONV2D class, see [reference](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html?highlight=nn%20conv2d#torch.nn.Conv2d).\n",
        "\n",
        "`torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)`\n",
        "\n",
        "A color image is seen as a rectangular box whose width and height are measured by the number of pixels from those dimensions. The three layers of colours (RGB) interpreted by CNNs are referred to as channels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0jbRNdjVfys"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "\n",
        "        #Designed to ensure that adjacent pixels are either all 0s or all active\n",
        "        #with an input probability\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x): # x is the input\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        \n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        output = F.log_softmax(x, dim = 1)\n",
        "        return output"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRcjK5yv2adz"
      },
      "source": [
        "### Pass data through your model to test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiI2wyEfcYbl",
        "outputId": "a7507c80-b50c-49ae-d667-ad24c1b634ab"
      },
      "source": [
        "input = torch.rand((1, 1, 28, 28)) #28x28x1 -> 1 channel (The MNIST)grayscale\n",
        "my_net = Net()\n",
        "output = my_net(input)\n",
        "# print((\"Input:\\n {}\").format(input))\n",
        "print((\"Labels predict:\\n {}\").format(output))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels predict:\n",
            " tensor([[-2.2877, -2.3330, -2.2935, -2.2946, -2.3128, -2.2188, -2.4090, -2.2306,\n",
            "         -2.2973, -2.3628]], grad_fn=<LogSoftmaxBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfABbDNQ3tKy"
      },
      "source": [
        "Finally, each number in this resulting tensor equates to the prediction of the 10 labels the input tensor is associated to.\n",
        "\n"
      ]
    }
  ]
}